{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>PCA for Identifying Key Variables in Donor Funding Analysis<center><h1>\n",
    "\n",
    "\n",
    "<img src=\"files/images/logo.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a).Objective\n",
    "The objective of this task is to develop a model to address the growing number of referrals at the Anderson Cancer Center. The model's first step is to identify essential variables for securing donor funding. Principal Component Analysis (PCA) has been chosen as the most suitable technique for this task. The following tasks will be implemented:\n",
    "- PCA Implementation:\n",
    "\n",
    "Utilize PCA to demonstrate how essential variables can be acquired from the cancer dataset available from sklearn.datasets.\n",
    "\n",
    "- Dimensionality Reduction:\n",
    "\n",
    "Reduce the dataset into 2 PCA components for the project.\n",
    "\n",
    "- Implement logistic regression for prediction.\n",
    "\n",
    "Implement a logistic regression for a defined prediction on the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b). Background\n",
    "Over the past few months, the number of referral cases at the Anderson Cancer Center has been growing rapidly. In order to provide a comprehensive and integrated health service for the people,the center has identified the need for using data to diagnose this growth, and to communicate the findings to simulate donor funding. This study aims to develop a model that will aid the center in addressing the growing number of referrals and identify the key variables that will appeal to donor funding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c). An Overview of PCA\n",
    "Principal Component Analysis (PCA) is a dimensionality reduction technique that is used to reduce the number of dimensions in a large dataset while retaining the original information. The \"Curse of Dimensionality\" is a common problem in machine learning. Many dimensions in a dataset often lead to overfitting (where a model fits too closely) and or multicollinearity (where variables are related, affecting model performance). PCA irons out these problems by extracting the most informative features from large datasets while preserving the most relevant information from the initial dataset (https://www.ibm.com/topics/principal-component-analysis).\n",
    "\n",
    "This statistical technique involves both linear algebra and matrix operations, and it transforms the original dataset into a new coordinate system that is structured by the principal components. The eigenvectors and eigenvalues from the covariance matrix that underpin the principal components allow for the analysis of these linear transformations.\n",
    "<img src=\"files/images/pca.png\">\n",
    "Figure: Illustration of PCA. (Source: IBM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Exploration\n",
    "We will be using the cancer dataset available from sklearn.datasets. We start by downloading the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the required libraries\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "\n",
    "# Load the breast cancer dataset from sklearn\n",
    "cancer_data = load_breast_cancer()\n",
    "\n",
    "# Create a DataFrame with the features and target variable\n",
    "cancer_df = pd.DataFrame(cancer_data.data, columns=cancer_data.feature_names)\n",
    "cancer_df['target'] = cancer_data.target\n",
    "\n",
    "# Display the first five rows\n",
    "cancer_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The breast cancer dataset has 30 columns. The dataset characteristics are defined as:\n",
    "\n",
    "Source (https://scikit-learn.org/1.5/datasets/toy_dataset.html#breast-cancer-dataset)\n",
    "\n",
    "- Number of Instances: 569\n",
    "\n",
    "- Number of Attributes: 30 numeric, predictive attributes and the class\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "- radius (mean of distances from center to points on the perimeter)\n",
    "\n",
    "- texture (standard deviation of gray-scale values)\n",
    "\n",
    "- perimeter\n",
    "\n",
    "- area\n",
    "\n",
    "- smoothness (local variation in radius lengths)\n",
    "\n",
    "- compactness (perimeter^2 / area - 1.0)\n",
    "\n",
    "- concavity (severity of concave portions of the contour)\n",
    "\n",
    "- concave points (number of concave portions of the contour)\n",
    "\n",
    "- symmetry\n",
    "\n",
    "- fractal dimension (“coastline approximation” - 1)\n",
    "\n",
    "The target column indicates whether the case is malignant (0) or benign (1). Benign tumors are noncancerous, while malignant tumors are cancerous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean radius              569 non-null    float64\n",
      " 1   mean texture             569 non-null    float64\n",
      " 2   mean perimeter           569 non-null    float64\n",
      " 3   mean area                569 non-null    float64\n",
      " 4   mean smoothness          569 non-null    float64\n",
      " 5   mean compactness         569 non-null    float64\n",
      " 6   mean concavity           569 non-null    float64\n",
      " 7   mean concave points      569 non-null    float64\n",
      " 8   mean symmetry            569 non-null    float64\n",
      " 9   mean fractal dimension   569 non-null    float64\n",
      " 10  radius error             569 non-null    float64\n",
      " 11  texture error            569 non-null    float64\n",
      " 12  perimeter error          569 non-null    float64\n",
      " 13  area error               569 non-null    float64\n",
      " 14  smoothness error         569 non-null    float64\n",
      " 15  compactness error        569 non-null    float64\n",
      " 16  concavity error          569 non-null    float64\n",
      " 17  concave points error     569 non-null    float64\n",
      " 18  symmetry error           569 non-null    float64\n",
      " 19  fractal dimension error  569 non-null    float64\n",
      " 20  worst radius             569 non-null    float64\n",
      " 21  worst texture            569 non-null    float64\n",
      " 22  worst perimeter          569 non-null    float64\n",
      " 23  worst area               569 non-null    float64\n",
      " 24  worst smoothness         569 non-null    float64\n",
      " 25  worst compactness        569 non-null    float64\n",
      " 26  worst concavity          569 non-null    float64\n",
      " 27  worst concave points     569 non-null    float64\n",
      " 28  worst symmetry           569 non-null    float64\n",
      " 29  worst fractal dimension  569 non-null    float64\n",
      " 30  target                   569 non-null    int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 137.9 KB\n"
     ]
    }
   ],
   "source": [
    "# Check the dimensions of the dataframe\n",
    "cancer_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Handle Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the dataset has missing values\n",
    "cancer_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing values in the dataset. Next we will scale and standardize the data since PCA is sensitive to the scale of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scaling and Standardization\n",
    "Normalization and scaling are essential steps in data preprocessing. Scaling data allows us to transform the data into a new scale without changing the shape of the distribution. It is useful for data that has a wide range of measurements. We will use the Standardscaler class from the sklearn module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Data\n",
      "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "0          17.99         10.38          122.80     1001.0          0.11840   \n",
      "1          20.57         17.77          132.90     1326.0          0.08474   \n",
      "2          19.69         21.25          130.00     1203.0          0.10960   \n",
      "3          11.42         20.38           77.58      386.1          0.14250   \n",
      "4          20.29         14.34          135.10     1297.0          0.10030   \n",
      "..           ...           ...             ...        ...              ...   \n",
      "564        21.56         22.39          142.00     1479.0          0.11100   \n",
      "565        20.13         28.25          131.20     1261.0          0.09780   \n",
      "566        16.60         28.08          108.30      858.1          0.08455   \n",
      "567        20.60         29.33          140.10     1265.0          0.11780   \n",
      "568         7.76         24.54           47.92      181.0          0.05263   \n",
      "\n",
      "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "0             0.27760         0.30010              0.14710         0.2419   \n",
      "1             0.07864         0.08690              0.07017         0.1812   \n",
      "2             0.15990         0.19740              0.12790         0.2069   \n",
      "3             0.28390         0.24140              0.10520         0.2597   \n",
      "4             0.13280         0.19800              0.10430         0.1809   \n",
      "..                ...             ...                  ...            ...   \n",
      "564           0.11590         0.24390              0.13890         0.1726   \n",
      "565           0.10340         0.14400              0.09791         0.1752   \n",
      "566           0.10230         0.09251              0.05302         0.1590   \n",
      "567           0.27700         0.35140              0.15200         0.2397   \n",
      "568           0.04362         0.00000              0.00000         0.1587   \n",
      "\n",
      "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
      "0                   0.07871  ...          17.33           184.60      2019.0   \n",
      "1                   0.05667  ...          23.41           158.80      1956.0   \n",
      "2                   0.05999  ...          25.53           152.50      1709.0   \n",
      "3                   0.09744  ...          26.50            98.87       567.7   \n",
      "4                   0.05883  ...          16.67           152.20      1575.0   \n",
      "..                      ...  ...            ...              ...         ...   \n",
      "564                 0.05623  ...          26.40           166.10      2027.0   \n",
      "565                 0.05533  ...          38.25           155.00      1731.0   \n",
      "566                 0.05648  ...          34.12           126.70      1124.0   \n",
      "567                 0.07016  ...          39.42           184.60      1821.0   \n",
      "568                 0.05884  ...          30.37            59.16       268.6   \n",
      "\n",
      "     worst smoothness  worst compactness  worst concavity  \\\n",
      "0             0.16220            0.66560           0.7119   \n",
      "1             0.12380            0.18660           0.2416   \n",
      "2             0.14440            0.42450           0.4504   \n",
      "3             0.20980            0.86630           0.6869   \n",
      "4             0.13740            0.20500           0.4000   \n",
      "..                ...                ...              ...   \n",
      "564           0.14100            0.21130           0.4107   \n",
      "565           0.11660            0.19220           0.3215   \n",
      "566           0.11390            0.30940           0.3403   \n",
      "567           0.16500            0.86810           0.9387   \n",
      "568           0.08996            0.06444           0.0000   \n",
      "\n",
      "     worst concave points  worst symmetry  worst fractal dimension  target  \n",
      "0                  0.2654          0.4601                  0.11890       0  \n",
      "1                  0.1860          0.2750                  0.08902       0  \n",
      "2                  0.2430          0.3613                  0.08758       0  \n",
      "3                  0.2575          0.6638                  0.17300       0  \n",
      "4                  0.1625          0.2364                  0.07678       0  \n",
      "..                    ...             ...                      ...     ...  \n",
      "564                0.2216          0.2060                  0.07115       0  \n",
      "565                0.1628          0.2572                  0.06637       0  \n",
      "566                0.1418          0.2218                  0.07820       0  \n",
      "567                0.2650          0.4087                  0.12400       0  \n",
      "568                0.0000          0.2871                  0.07039       1  \n",
      "\n",
      "[569 rows x 31 columns]\n",
      "\n",
      "Normalized Data\n",
      "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "0       1.097064     -2.073335        1.269934   0.984375         1.568466   \n",
      "1       1.829821     -0.353632        1.685955   1.908708        -0.826962   \n",
      "2       1.579888      0.456187        1.566503   1.558884         0.942210   \n",
      "3      -0.768909      0.253732       -0.592687  -0.764464         3.283553   \n",
      "4       1.750297     -1.151816        1.776573   1.826229         0.280372   \n",
      "..           ...           ...             ...        ...              ...   \n",
      "564     2.110995      0.721473        2.060786   2.343856         1.041842   \n",
      "565     1.704854      2.085134        1.615931   1.723842         0.102458   \n",
      "566     0.702284      2.045574        0.672676   0.577953        -0.840484   \n",
      "567     1.838341      2.336457        1.982524   1.735218         1.525767   \n",
      "568    -1.808401      1.221792       -1.814389  -1.347789        -3.112085   \n",
      "\n",
      "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "0            3.283515        2.652874             2.532475       2.217515   \n",
      "1           -0.487072       -0.023846             0.548144       0.001392   \n",
      "2            1.052926        1.363478             2.037231       0.939685   \n",
      "3            3.402909        1.915897             1.451707       2.867383   \n",
      "4            0.539340        1.371011             1.428493      -0.009560   \n",
      "..                ...             ...                  ...            ...   \n",
      "564          0.219060        1.947285             2.320965      -0.312589   \n",
      "565         -0.017833        0.693043             1.263669      -0.217664   \n",
      "566         -0.038680        0.046588             0.105777      -0.809117   \n",
      "567          3.272144        3.296944             2.658866       2.137194   \n",
      "568         -1.150752       -1.114873            -1.261820      -0.820070   \n",
      "\n",
      "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
      "0                  2.255747  ...      -1.359293         2.303601    2.001237   \n",
      "1                 -0.868652  ...      -0.369203         1.535126    1.890489   \n",
      "2                 -0.398008  ...      -0.023974         1.347475    1.456285   \n",
      "3                  4.910919  ...       0.133984        -0.249939   -0.550021   \n",
      "4                 -0.562450  ...      -1.466770         1.338539    1.220724   \n",
      "..                      ...  ...            ...              ...         ...   \n",
      "564               -0.931027  ...       0.117700         1.752563    2.015301   \n",
      "565               -1.058611  ...       2.047399         1.421940    1.494959   \n",
      "566               -0.895587  ...       1.374854         0.579001    0.427906   \n",
      "567                1.043695  ...       2.237926         2.303601    1.653171   \n",
      "568               -0.561032  ...       0.764190        -1.432735   -1.075813   \n",
      "\n",
      "     worst smoothness  worst compactness  worst concavity  \\\n",
      "0            1.307686           2.616665         2.109526   \n",
      "1           -0.375612          -0.430444        -0.146749   \n",
      "2            0.527407           1.082932         0.854974   \n",
      "3            3.394275           3.893397         1.989588   \n",
      "4            0.220556          -0.313395         0.613179   \n",
      "..                ...                ...              ...   \n",
      "564          0.378365          -0.273318         0.664512   \n",
      "565         -0.691230          -0.394820         0.236573   \n",
      "566         -0.809587           0.350735         0.326767   \n",
      "567          1.430427           3.904848         3.197605   \n",
      "568         -1.859019          -1.207552        -1.305831   \n",
      "\n",
      "     worst concave points  worst symmetry  worst fractal dimension    target  \n",
      "0                2.296076        2.750622                 1.937015 -1.297676  \n",
      "1                1.087084       -0.243890                 0.281190 -1.297676  \n",
      "2                1.955000        1.152255                 0.201391 -1.297676  \n",
      "3                2.175786        6.046041                 4.935010 -1.297676  \n",
      "4                0.729259       -0.868353                -0.397100 -1.297676  \n",
      "..                    ...             ...                      ...       ...  \n",
      "564              1.629151       -1.360158                -0.709091 -1.297676  \n",
      "565              0.733827       -0.531855                -0.973978 -1.297676  \n",
      "566              0.414069       -1.104549                -0.318409 -1.297676  \n",
      "567              2.289985        1.919083                 2.219635 -1.297676  \n",
      "568             -1.745063       -0.048138                -0.751207  0.770609  \n",
      "\n",
      "[569 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# create a StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# fit and transform the data\n",
    "scaled_data = scaler.fit_transform(cancer_df)\n",
    "\n",
    "# create a new DataFrame with the scaled data\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=cancer_df.columns)\n",
    "\n",
    "print(\"Raw Data\")\n",
    "print(cancer_df)\n",
    "print(\"\\nNormalized Data\")\n",
    "print(scaled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis (EDA), is helpful in \"taking a peak\" at the data before any assumption are made about the data. It can assist in identifying errors, detect outliers, identify trends and patterns and check for relationship between varibales. Exploratory analysis is essential in ensuring that the results are valid and applicable to the  business outcomes and goals. EDA also assists the stakeholders by confirming that the relevant questions are being asked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Visualizing Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Interpretation and Key Variable Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Conclusion and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
